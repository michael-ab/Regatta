{"path":".obsidian/plugins/text-extractor/cache/f42bb5ff86045cc3d097d22ae4f83ded.json","text":"Intro to Database Systems 15-445/15-645 Fall 2019 Andy Pavlo Computer Science Carnegie Mellon UniversityAP 13 Query Execution Part II CMU 15-445/645 (Fall 2019) A D M I N I S T R I V I A Homework #3 is due Today @ 11:59pm Mid-Term Exam is Wed Oct 16th @ 12:00pm Project #2 is due Sun Oct 20th @ 11:59pm 2 CMU 15-445/645 (Fall 2019) Q U E R Y E X E C U T I O N We discussed last class how to compose operators together to execute a query plan. We assumed that the queries execute with a single worker (e.g., thread). We now need to talk about how to execute with multiple workers… 3 R S R.id=S.id value>100 R.id, S.value ⨝ s p SELECT R.id, S.cdate FROM R JOIN S ON R.id = S.id WHERE S.value > 100 CMU 15-445/645 (Fall 2019) W H Y C A R E A B O U T PA R A L L E L E X E C U T I O N ? Increased performance. → Throughput → Latency Increased responsiveness and availability. Potentially lower total cost of ownership (TCO). 4 CMU 15-445/645 (Fall 2019) PA R A L L E L V S . D I S T R I B U T E D Database is spread out across multiple resources to improve different aspects of the DBMS. Appears as a single database instance to the application. → SQL query for a single-resource DBMS should generate same result on a parallel or distributed DBMS. CMU 15-445/645 (Fall 2019) PA R A L L E L V S . D I S T R I B U T E D Parallel DBMSs: → Resources are physically close to each other. → Resources communicate with high-speed interconnect. → Communication is assumed to cheap and reliable. Distributed DBMSs: → Resources can be far from each other. → Resources communicate using slow(er) interconnect. → Communication cost and problems cannot be ignored. CMU 15-445/645 (Fall 2019) T O D AY ' S A G E N D A Process Models Execution Parallelism I/O Parallelism 7 CMU 15-445/645 (Fall 2019) P R O C E S S M O D E L A DBMS’s process model defines how the system is architected to support concurrent requests from a multi-user application. A worker is the DBMS component that is responsible for executing tasks on behalf of the client and returning the results. 8 CMU 15-445/645 (Fall 2019) P R O C E S S M O D E L S Approach #1: Process per DBMS Worker Approach #2: Process Pool Approach #3: Thread per DBMS Worker 9 CMU 15-445/645 (Fall 2019) P R O C E S S P E R W O R K E R Each worker is a separate OS process. → Relies on OS scheduler. → Use shared-memory for global data structures. → A process crash doesn’t take down entire system. → Examples: IBM DB2, Postgres, Oracle 10 Dispatcher Worker CMU 15-445/645 (Fall 2019) P R O C E S S P O O L A worker uses any process that is free in a pool → Still relies on OS scheduler and shared memory. → Bad for CPU cache locality. → Examples: IBM DB2, Postgres (2015) 11 Worker PoolDispatcher CMU 15-445/645 (Fall 2019) T H R E A D P E R W O R K E R Single process with multiple worker threads. → DBMS manages its own scheduling. → May or may not use a dispatcher thread. → Thread crash (may) kill the entire system. → Examples: IBM DB2, MSSQL, MySQL, Oracle (2014) 12 Worker Threads CMU 15-445/645 (Fall 2019) P R O C E S S M O D E L S Using a multi-threaded architecture has several advantages: → Less overhead per context switch. → Do not have to manage shared memory. The thread per worker model does not mean that the DBMS supports intra-query parallelism. Andy is not aware of any new DBMS from last 10 years that doesn’t use threads unless they are Postgres forks. 13 CMU 15-445/645 (Fall 2019) S C H E D U L I N G For each query plan, the DBMS decides where, when, and how to execute it. → How many tasks should it use? → How many CPU cores should it use? → What CPU core should the tasks execute on? → Where should a task store its output? The DBMS always knows more than the OS. 14 CMU 15-445/645 (Fall 2019) I N T E R- V S . I N T R A - Q U E R Y PA R A L L E L I S M Inter-Query: Different queries are executed concurrently. → Increases throughput & reduces latency. Intra-Query: Execute the operations of a single query in parallel. → Decreases latency for long-running queries. CMU 15-445/645 (Fall 2019) I N T E R- Q U E R Y PA R A L L E L I S M Improve overall performance by allowing multiple queries to execute simultaneously. If queries are read-only, then this requires little coordination between queries. If multiple queries are updating the database at the same time, then this is hard to do correctly… 16 CMU 15-445/645 (Fall 2019) I N T R A - Q U E R Y PA R A L L E L I S M Improve the performance of a single query by executing its operators in parallel. Think of organization of operators in terms of a producer/consumer paradigm. There are parallel algorithms for every relational operator. → Can either have multiple threads access centralized data structures or use partitioning to divide work up. 17 CMU 15-445/645 (Fall 2019) PA R A L L E L G R A C E H A S H J O I N Use a separate worker to perform the join for each level of buckets for R and S after partitioning. 18 h1 ⋮ HTR h1 R(id,name) ⋮ HTS 0 1 2 max S(id,value,cdate) CMU 15-445/645 (Fall 2019) PA R A L L E L G R A C E H A S H J O I N Use a separate worker to perform the join for each level of buckets for R and S after partitioning. 18 h1 ⋮ HTR h1 R(id,name) ⋮ HTS 0 1 2 max S(id,value,cdate)1 2 3 n CMU 15-445/645 (Fall 2019) I N T R A - Q U E R Y PA R A L L E L I S M Approach #1: Intra-Operator (Horizontal) Approach #2: Inter-Operator (Vertical) Approach #3: Bushy 19 CMU 15-445/645 (Fall 2019) I N T R A - O P E R AT O R PA R A L L E L I S M Approach #1: Intra-Operator (Horizontal) → Decompose operators into independent fragments that perform the same function on different subsets of data. The DBMS inserts an exchange operator into the query plan to coalesce results from children operators. 20 CMU 15-445/645 (Fall 2019) I N T R A - O P E R AT O R PA R A L L E L I S M 21 SELECT * FROM A WHERE A.value > 99 A2A1 A3 1 2 3 s s s A svalue>99 Exchange 1 2 3 4 5Pages CMU 15-445/645 (Fall 2019) I N T R A - O P E R AT O R PA R A L L E L I S M 21 SELECT * FROM A WHERE A.value > 99 A2A1 A3 1 2 3 s s s A svalue>99 Exchange 1 2 3 4 5Pages Fragment CMU 15-445/645 (Fall 2019) I N T R A - O P E R AT O R PA R A L L E L I S M 21 SELECT * FROM A WHERE A.value > 99 A2A1 A3 1 2 3 s s s A svalue>99 Exchange 1 2 3 4 5Pages Next Next CMU 15-445/645 (Fall 2019) I N T R A - O P E R AT O R PA R A L L E L I S M 21 SELECT * FROM A WHERE A.value > 99 A2A1 A3 1 2 3 s s s A svalue>99 Exchange 1 2 3 4 5Pages Next Next CMU 15-445/645 (Fall 2019) I N T R A - O P E R AT O R PA R A L L E L I S M 21 SELECT * FROM A WHERE A.value > 99 A2A1 A3 1 2 3 s s s A svalue>99 Exchange 1 2 3 4 5Pages CMU 15-445/645 (Fall 2019) I N T R A - O P E R AT O R PA R A L L E L I S M 21 SELECT * FROM A WHERE A.value > 99 A2A1 A3 1 2 3 s s s A svalue>99 Exchange 1 2 3 4 5Pages CMU 15-445/645 (Fall 2019) E XC H A N G E O P E R AT O R Exchange Type #1 – Gather → Combine the results from multiple workers into a single output stream. → Query plan root must always be a gather exchange. Exchange Type #2 – Repartition → Reorganize multiple input streams across multiple output streams. Exchange Type #3 – Distribute → Split a single input stream into multiple output streams. 22 Source: Craig Freedman CMU 15-445/645 (Fall 2019) A B ⨝s p s I N T R A - O P E R AT O R PA R A L L E L I S M 23 SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 A2A1 A3 1 2 3 CMU 15-445/645 (Fall 2019) A B ⨝s p s I N T R A - O P E R AT O R PA R A L L E L I S M 23 SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 A2A1 A3 1 2 3 s s s CMU 15-445/645 (Fall 2019) A B ⨝s p s I N T R A - O P E R AT O R PA R A L L E L I S M 23 SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 A2A1 A3 Build HT Build HT Build HT 1 2 3 s s s CMU 15-445/645 (Fall 2019) A B ⨝s p s I N T R A - O P E R AT O R PA R A L L E L I S M 23 SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 A2A1 A3 Build HT Build HT Build HT 1 2 3 Exchange s s s CMU 15-445/645 (Fall 2019) A B ⨝s p s I N T R A - O P E R AT O R PA R A L L E L I S M 23 SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 A2A1 A3 Build HT Build HT Build HT B1 B2 1 2 3 4 5 Exchange s s s CMU 15-445/645 (Fall 2019) A B ⨝s p s I N T R A - O P E R AT O R PA R A L L E L I S M 23 SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 A2A1 A3 Build HT Build HT Build HT B1 B2 Partition Partition 1 2 3 4 5 Exchange Exchange s ss s s CMU 15-445/645 (Fall 2019) A B ⨝s p s I N T R A - O P E R AT O R PA R A L L E L I S M 23 SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 A2A1 A3 Build HT Build HT Build HT B1 B2 Partition Partition 1 2 3 4 5 ⨝ Exchange Exchange s ss s s CMU 15-445/645 (Fall 2019) A B ⨝s p s I N T R A - O P E R AT O R PA R A L L E L I S M 23 SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 A2A1 A3 Build HT Build HT Build HT B1 B2 Partition Partition 1 2 3 4 5 1 2 3 4 Probe HT Probe HT Probe HT Probe HT ⨝ Exchange Exchange Exchange s ss s s CMU 15-445/645 (Fall 2019) I N T E R- O P E R AT O R PA R A L L E L I S M Approach #2: Inter-Operator (Vertical) → Operations are overlapped in order to pipeline data from one stage to the next without materialization. Also called pipelined parallelism. 24 CMU 15-445/645 (Fall 2019) I N T E R- O P E R AT O R PA R A L L E L I S M 1 ⨝ for r1 ∊ outer: for r2 ∊ inner: emit(r1⨝r2) A B ⨝s p s SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 CMU 15-445/645 (Fall 2019) I N T E R- O P E R AT O R PA R A L L E L I S M 1 ⨝ for r1 ∊ outer: for r2 ∊ inner: emit(r1⨝r2) 2 p for r ∊ incoming: emit(pr) A B ⨝s p s SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 CMU 15-445/645 (Fall 2019) I N T E R- O P E R AT O R PA R A L L E L I S M 1 ⨝ for r1 ∊ outer: for r2 ∊ inner: emit(r1⨝r2) 2 p for r ∊ incoming: emit(pr) A B ⨝s p s SELECT A.id, B.value FROM A JOIN B ON A.id = B.id WHERE A.value < 99 AND B.value > 100 CMU 15-445/645 (Fall 2019) B U S H Y PA R A L L E L I S M Approach #3: Bushy Parallelism → Extension of inter-operator parallelism where workers execute multiple operators from different segments of a query plan at the same time. → Still need exchange operators to combine intermediate results from segments. 26 SELECT * FROM A JOIN B JOIN C JOIN D A ⨝ B ⨝ C D ⨝ Exchange Exchange Exchange ⨝ 3 4 1 2 CMU 15-445/645 (Fall 2019) O B S E R VAT I O N Using additional processes/threads to execute queries in parallel won't help if the disk is always the main bottleneck. → Can make things worse if each worker is reading different segments of disk. 27 CMU 15-445/645 (Fall 2019) I / O PA R A L L E L I S M Split the DBMS installation across multiple storage devices. → Multiple Disks per Database → One Database per Disk → One Relation per Disk → Split Relation across Multiple Disks 28 CMU 15-445/645 (Fall 2019) M U LT I - D I S K PA R A L L E L I S M Configure OS/hardware to store the DBMS's files across multiple storage devices. → Storage Appliances → RAID Configuration This is transparent to the DBMS. 29 page1 page4 page2 page5 page3 page6 RAID 0 (Stripping) CMU 15-445/645 (Fall 2019) M U LT I - D I S K PA R A L L E L I S M Configure OS/hardware to store the DBMS's files across multiple storage devices. → Storage Appliances → RAID Configuration This is transparent to the DBMS. 29 page2 page1 page2 page1 page2 page1 RAID 1 (Mirroring) CMU 15-445/645 (Fall 2019) D ATA B A S E PA R T I T I O N I N G Some DBMSs allow you specify the disk location of each individual database. → The buffer pool manager maps a page to a disk location. This is also easy to do at the filesystem level if the DBMS stores each database in a separate directory. → The log file might be shared though 30 CMU 15-445/645 (Fall 2019) PA R T I T I O N I N G Split single logical table into disjoint physical segments that are stored/managed separately. Ideally partitioning is transparent to the application. → The application accesses logical tables and does not care how things are stored. → Not always true in distributed DBMSs. 31 CMU 15-445/645 (Fall 2019) V E R T I C A L PA R T I T I O N I N G Store a table’s attributes in a separate location (e.g., file, disk volume). Have to store tuple information to reconstruct the original record. 32 Tuple#1 Tuple#2 Tuple#3 Tuple#4 attr1 attr2 attr3 attr1 attr2 attr3 attr1 attr2 attr3 attr1 attr2 attr3 attr4 attr4 attr4 attr4 CREATE TABLE foo ( attr1 INT, attr2 INT, attr3 INT, attr4 TEXT ); CMU 15-445/645 (Fall 2019) V E R T I C A L PA R T I T I O N I N G Store a table’s attributes in a separate location (e.g., file, disk volume). Have to store tuple information to reconstruct the original record. 32 Tuple#1 Tuple#2 Tuple#3 Tuple#4 attr1 attr2 attr3 attr1 attr2 attr3 attr1 attr2 attr3 attr1 attr2 attr3 attr4 attr4 attr4 attr4 Tuple#1 Tuple#2 Tuple#3 Tuple#4 Partition #1 Partition #2 CREATE TABLE foo ( attr1 INT, attr2 INT, attr3 INT, attr4 TEXT ); CMU 15-445/645 (Fall 2019) H O R I Z O N TA L PA R T I T I O N I N G Divide the tuples of a table up into disjoint segments based on some partitioning key. → Hash Partitioning → Range Partitioning → Predicate Partitioning 33 attr1 attr2 attr3 attr1 attr2 attr3 Tuple#1 Tuple#2 attr4 attr4 attr1 attr2 attr3 attr1 attr2 attr3 Tuple#3 Tuple#4 attr4 attr4 CREATE TABLE foo ( attr1 INT, attr2 INT, attr3 INT, attr4 TEXT ); CMU 15-445/645 (Fall 2019) H O R I Z O N TA L PA R T I T I O N I N G Divide the tuples of a table up into disjoint segments based on some partitioning key. → Hash Partitioning → Range Partitioning → Predicate Partitioning 33 attr1 attr2 attr3 attr1 attr2 attr3 Tuple#1 Tuple#2 attr4 attr4 attr1 attr2 attr3 attr1 attr2 attr3 Tuple#3 Tuple#4 attr4 attr4 Partition #1 Partition #2 CREATE TABLE foo ( attr1 INT, attr2 INT, attr3 INT, attr4 TEXT ); CMU 15-445/645 (Fall 2019) C O N C L U S I O N Parallel execution is important. (Almost) every DBMS support this. This is really hard to get right. → Coordination Overhead → Scheduling → Concurrency Issues → Resource Contention 34 CMU 15-445/645 (Fall 2019) M I D T E R M E X A M Who: You What: Midterm Exam When: Wed Oct 16th @ 12:00pm ‐ 1:20pm Where: MM 103 Why: https://youtu.be/GHPB1eCROSA Covers up to Query Execution II (inclusive). → Please email Andy if you need special accommodations. → https://15445.courses.cs.cmu.edu/fall2019/midterm- guide.html 35 CMU 15-445/645 (Fall 2019) M I D T E R M E X A M What to bring: → CMU ID → Calculator → One 8.5x11\" page of handwritten notes (double-sided) What not to bring: → Live animals → Your wet laundry → Votive Candles (aka \"Jennifer Lopez\" Candles) 36 CMU 15-445/645 (Fall 2019) R E L AT I O N A L M O D E L Integrity Constraints Relation Algebra 37 CMU 15-445/645 (Fall 2019) S Q L Basic operations: → SELECT / INSERT / UPDATE / DELETE → WHERE predicates → Output control More complex operations: → Joins → Aggregates → Common Table Expressions 38 CMU 15-445/645 (Fall 2019) S T O R A G E Buffer Management Policies → LRU / MRU / CLOCK On-Disk File Organization → Heaps → Linked Lists Page Layout → Slotted Pages → Log-Structured 39 CMU 15-445/645 (Fall 2019) H A S H I N G Static Hashing → Linear Probing → Robin Hood → Cuckoo Hashing Dynamic Hashing → Extendible Hashing → Linear Hashing 40 CMU 15-445/645 (Fall 2019) T R E E I N D E X E S B+Tree → Insertions / Deletions → Splits / Merges → Difference with B-Tree → Latch Crabbing / Coupling Radix Trees 41 CMU 15-445/645 (Fall 2019) S O R T I N G Two-way External Merge Sort General External Merge Sort Cost to sort different data sets with different number of buffers. 42 CMU 15-445/645 (Fall 2019) J O I N S Nested Loop Variants Sort-Merge Hash Execution costs under different conditions. 43 CMU 15-445/645 (Fall 2019) Q U E R Y P R O C E S S I N G Processing Models → Advantages / Disadvantages Parallel Execution → Inter- vs. Intra-Operator Parallelism 44 CMU 15-445/645 (Fall 2019) N E X T C L A S S Query Planning & Optimization 45","libVersion":"0.2.2","langs":""}