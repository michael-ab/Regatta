{"path":".obsidian/plugins/text-extractor/cache/f0b8c0e17bb9f14f5233adec825578e3.json","text":"Intro to Database Systems 15-445/15-645 Fall 2019 Andy Pavlo Computer Science Carnegie Mellon UniversityAP 10 Sorting & Aggregations CMU 15-445/645 (Fall 2019) A D M I N I S T R I V I A Homework #3 is due Wed Oct 9th @ 11:59pm Mid-Term Exam is Wed Oct 16th @ 12:00pm Project #2 is due Sun Oct 20th @ 11:59pm 2 CMU 15-445/645 (Fall 2019) Query Planning Operator Execution Access Methods Buffer Pool Manager Disk Manager C O U R S E S TAT U S We are now going to talk about how to execute queries using table heaps and indexes. Next two weeks: → Operator Algorithms → Query Processing Models → Runtime Architectures 3 CMU 15-445/645 (Fall 2019) Q U E R Y P L A N The operators are arranged in a tree. Data flows from the leaves of the tree up towards the root. The output of the root node is the result of the query. 4 SELECT A.id, B.value FROM A, B WHERE A.id = B.id AND B.value > 100 A B A.id=B.id value>100 A.id, B.value ⨝ s p CMU 15-445/645 (Fall 2019) D I S K- O R I E N T E D D B M S Just like it cannot assume that a table fits entirely in memory, a disk-oriented DBMS cannot assume that the results of a query fits in memory. We are going use on the buffer pool to implement algorithms that need to spill to disk. We are also going to prefer algorithms that maximize the amount of sequential access. 5 CMU 15-445/645 (Fall 2019) T O D AY ' S A G E N D A External Merge Sort Aggregations 6 CMU 15-445/645 (Fall 2019) W H Y D O W E N E E D T O S O R T ? Tuples in a table have no specific order. But queries often want to retrieve tuples in a specific order. → Trivial to support duplicate elimination (DISTINCT). → Bulk loading sorted tuples into a B+Tree index is faster. → Aggregations (GROUP BY). 7 CMU 15-445/645 (Fall 2019) S O R T I N G A L G O R I T H M S If data fits in memory, then we can use a standard sorting algorithm like quick-sort. If data does not fit in memory, then we need to use a technique that is aware of the cost of writing data out to disk… 8 CMU 15-445/645 (Fall 2019) E X T E R N A L M E R G E S O R T Divide-and-conquer sorting algorithm that splits the data set into separate runs and then sorts them individually. Phase #1 – Sorting → Sort blocks of data that fit in main-memory and then write back the sorted blocks to a file on disk. Phase #2 – Merging → Combine sorted sub-files into a single larger file. 9 CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T We will start with a simple example of a 2-way external merge sort. → \"2\" represents the number of runs that we are going to merge into a new run for each pass. Data set is broken up into N pages. The DBMS has a finite number of B buffer pages to hold input and output data. 10 CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T Pass #0 → Read every B pages of the table into memory → Sort pages into runs and write them back to disk. Memory Disk 11 Page #1 Page #2 CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T Pass #0 → Read every B pages of the table into memory → Sort pages into runs and write them back to disk. Memory Disk 11 Page #1 Page #2 CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T Pass #0 → Read every B pages of the table into memory → Sort pages into runs and write them back to disk. Memory Disk 11 Page #1 Page #2 Sorted Run CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T Pass #0 → Read every B pages of the table into memory → Sort pages into runs and write them back to disk. Memory Memory Disk 11 Page #1 Page #2 Sorted Run CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T Pass #0 → Read every B pages of the table into memory → Sort pages into runs and write them back to disk. Memory Memory Disk 11 Page #1 Page #2 Sorted Run CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T Pass #0 → Read every B pages of the table into memory → Sort pages into runs and write them back to disk. Pass #1,2,3,… → Recursively merges pairs of runs into runs twice as long. → Uses three buffer pages (2 for input pages, 1 for output). Memory Memory Memory Disk 11 Page #1 Page #2 Sorted Run CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T Pass #0 → Read every B pages of the table into memory → Sort pages into runs and write them back to disk. Pass #1,2,3,… → Recursively merges pairs of runs into runs twice as long. → Uses three buffer pages (2 for input pages, 1 for output). Memory Memory Memory Disk 11 Page #1 Page #2 Sorted Run CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T Pass #0 → Read every B pages of the table into memory → Sort pages into runs and write them back to disk. Pass #1,2,3,… → Recursively merges pairs of runs into runs twice as long. → Uses three buffer pages (2 for input pages, 1 for output). Memory Memory Memory Disk 11 Page #1 Page #2 Final Result Sorted Run CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T In each pass, we read and write each page in file. Number of passes = 1 + ⌈ log2 N ⌉ Total I/O cost = 2N ∙ (# of passes) 12 1-PAGE RUNS PASS #0 2-PAGE RUNS PASS #1 4-PAGE RUNS PASS #2 8-PAGE RUNS PASS #3 3,4 2,6 4,9 7,8 5,6 1,3 2 ∅ 6,2 9,4 8,7 5,6 3,1 2 ∅3,4 2,3 4,6 4,7 8,9 1,3 5,6 2 ∅ 4,4 6,7 8,9 2,3 1,2 3,5 6 ∅ 1,2 2,3 3,4 4,5 6,6 7,8 9 ∅ EOF CMU 15-445/645 (Fall 2019) 2 -WAY E X T E R N A L M E R G E S O R T This algorithm only requires three buffer pages to perform the sorting (B=3). But even if we have more buffer space available (B>3), it does not effectively utilize them… 13 CMU 15-445/645 (Fall 2019) D O U B L E B U F F E R I N G O P T I M I Z AT I O N Prefetch the next run in the background and store it in a second buffer while the system is processing the current run. → Reduces the wait time for I/O requests at each step by continuously utilizing the disk. 14 Memory Disk Page #1 Page #2 CMU 15-445/645 (Fall 2019) D O U B L E B U F F E R I N G O P T I M I Z AT I O N Prefetch the next run in the background and store it in a second buffer while the system is processing the current run. → Reduces the wait time for I/O requests at each step by continuously utilizing the disk. 14 Memory Disk Page #1 Page #2 CMU 15-445/645 (Fall 2019) G E N E R A L E X T E R N A L M E R G E S O R T Pass #0 → Use B buffer pages. → Produce ⌈N / B⌉ sorted runs of size B Pass #1,2,3,… → Merge B-1 runs (i.e., K-way merge). Number of passes = 1 + ⌈ logB-1 ⌈N / B⌉ ⌉ Total I/O Cost = 2N ∙ (# of passes) 15 CMU 15-445/645 (Fall 2019) G E N E R A L E X T E R N A L M E R G E S O R T Pass #0 → Use B buffer pages. → Produce ⌈N / B⌉ sorted runs of size B Pass #1,2,3,… → Merge B-1 runs (i.e., K-way merge). Number of passes = 1 + ⌈ logB-1 ⌈N / B⌉ ⌉ Total I/O Cost = 2N ∙ (# of passes) 15 CMU 15-445/645 (Fall 2019) E X A M P L E Sort 108 pages with 5 buffer pages: N=108, B=5 → Pass #0: ⌈N / B⌉ = ⌈108 / 5⌉ = 22 sorted runs of 5 pages each (last run is only 3 pages). → Pass #1: ⌈N’ / B-1⌉ = ⌈22 / 4⌉ = 6 sorted runs of 20 pages each (last run is only 8 pages). → Pass #2: ⌈N’’ / B-1⌉ = ⌈6 / 4⌉ = 2 sorted runs, first one has 80 pages and second one has 28 pages. → Pass #3: Sorted file of 108 pages. 1+⌈ logB-1⌈N / B⌉ ⌉ = 1+⌈log4 22⌉ = 1+⌈2.229...⌉ = 4 passes 16 CMU 15-445/645 (Fall 2019) U S I N G B + T R E E S F O R S O R T I N G If the table that must be sorted already has a B+Tree index on the sort attribute(s), then we can use that to accelerate sorting. Retrieve tuples in desired sort order by simply traversing the leaf pages of the tree. Cases to consider: → Clustered B+Tree → Unclustered B+Tree 18 CMU 15-445/645 (Fall 2019) C A S E # 1 C L U S T E R E D B + T R E E Traverse to the left-most leaf page, and then retrieve tuples from all leaf pages. This is always better than external sorting because there is no computational cost and all disk access is sequential. 19 B+Tree Index 101 102 103 104 Tuple Pages CMU 15-445/645 (Fall 2019) C A S E # 2 U N C L U S T E R E D B + T R E E Chase each pointer to the page that contains the data. This is almost always a bad idea. In general, one I/O per data record. 20 101 102 103 104 Tuple Pages B+Tree Index CMU 15-445/645 (Fall 2019) A G G R E G AT I O N S Collapse multiple tuples into a single scalar value. Two implementation choices: → Sorting → Hashing 21 CMU 15-445/645 (Fall 2019) cid 15-445 15-445 15-721 15-826 S O R T I N G A G G R E G AT I O N 22 Remove Columns SortFilter sid cid grade 53666 15-445 C 53688 15-826 B 53666 15-721 C 53655 15-445 C cid 15-445 15-826 15-721 15-445 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') ORDER BY cid sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) CMU 15-445/645 (Fall 2019) cid 15-445 15-445 15-721 15-826 S O R T I N G A G G R E G AT I O N 22 Remove Columns Sort Eliminate Dupes Filter sid cid grade 53666 15-445 C 53688 15-826 B 53666 15-721 C 53655 15-445 C cid 15-445 15-826 15-721 15-445 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') ORDER BY cid sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) CMU 15-445/645 (Fall 2019) cid 15-445 15-445 15-721 15-826 S O R T I N G A G G R E G AT I O N 22 Remove Columns Sort Eliminate Dupes X Filter sid cid grade 53666 15-445 C 53688 15-826 B 53666 15-721 C 53655 15-445 C cid 15-445 15-826 15-721 15-445 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') ORDER BY cid sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) CMU 15-445/645 (Fall 2019) A LT E R N AT I V E S T O S O R T I N G What if we don’t need the data to be ordered? → Forming groups in GROUP BY (no ordering) → Removing duplicates in DISTINCT (no ordering) Hashing is a better alternative in this scenario. → Only need to remove duplicates, no need for ordering. → Can be computationally cheaper than sorting. 23 CMU 15-445/645 (Fall 2019) H A S H I N G A G G R E G AT E Populate an ephemeral hash table as the DBMS scans the table. For each record, check whether there is already an entry in the hash table: → DISTINCT: Discard duplicate. → GROUP BY: Perform aggregate computation. If everything fits in memory, then it is easy. If the DBMS must spill data to disk, then we need to be smarter… 24 CMU 15-445/645 (Fall 2019) E X T E R N A L H A S H I N G A G G R E G AT E Phase #1 – Partition → Divide tuples into buckets based on hash key. → Write them out to disk when they get full. Phase #2 – ReHash → Build in-memory hash table for each partition and compute the aggregation. 25 CMU 15-445/645 (Fall 2019) P H A S E # 1 PA R T I T I O N Use a hash function h1 to split tuples into partitions on disk. → We know that all matches live in the same partition. → Partitions are \"spilled\" to disk via output buffers. Assume that we have B buffers. We will use B-1 buffers for the partitions and 1 buffer for the input data. 26 CMU 15-445/645 (Fall 2019) P H A S E # 1 PA R T I T I O N 27 Remove Columns Filter sid cid grade 53666 15-445 C 53688 15-826 B 53666 15-721 C 53655 15-445 C cid 15-445 15-826 15-721 15-445 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') 15-445 15-445 15-445 15-445 15-445 15-826 15-826 15-721 ⋮ h1 B-1 partitions sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) ⋮ CMU 15-445/645 (Fall 2019) P H A S E # 2 R E H A S H For each partition on disk: → Read it into memory and build an in-memory hash table based on a second hash function h2. → Then go through each bucket of this hash table to bring together matching tuples. This assumes that each partition fits in memory. 28 CMU 15-445/645 (Fall 2019) P H A S E # 2 R E H A S H 29 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') 15-445 15-445 15-445 15-445 15-445 15-826 15-826 ⋮ Phase #1 Buckets sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) CMU 15-445/645 (Fall 2019) P H A S E # 2 R E H A S H 29 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') 15-445 15-445 15-445 15-445 15-445 15-826 15-826 ⋮ Phase #1 Buckets sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) CMU 15-445/645 (Fall 2019) P H A S E # 2 R E H A S H 29 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') 15-445 15-445 15-445 15-445 15-445 15-826 15-826 ⋮ h2 Phase #1 Buckets cid 15-445 Hash Table sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) CMU 15-445/645 (Fall 2019) P H A S E # 2 R E H A S H 29 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') 15-445 15-445 15-445 15-445 15-445 15-826 15-826 ⋮ h2 h2 Phase #1 Buckets cid 15-445 Hash Table sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) 15-826 CMU 15-445/645 (Fall 2019) P H A S E # 2 R E H A S H 29 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') 15-445 15-445 15-445 15-445 15-445 15-826 15-826 ⋮ h2 h2 Phase #1 Buckets cid 15-445 cid 15-445 15-826 Hash Table sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) Final Result15-826 CMU 15-445/645 (Fall 2019) P H A S E # 2 R E H A S H 29 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') 15-721 15-445 15-445 15-445 15-445 15-445 15-826 15-826 ⋮ h2 h2 Phase #1 Buckets cid 15-445 cid 15-445 15-826 Hash Table sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) Final Result15-826 CMU 15-445/645 (Fall 2019) P H A S E # 2 R E H A S H 29 SELECT DISTINCT cid FROM enrolled WHERE grade IN ('B','C') 15-721 15-445 15-445 15-445 15-445 15-445 15-826 15-826 ⋮ h2 h2 h2 Phase #1 Buckets cid 15-445 15-826 sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53666 15-721 C 53655 15-445 C enrolled(sid,cid,grade) Final Result cid 15-721 Hash Table 15-721 CMU 15-445/645 (Fall 2019) H A S H I N G S U M M A R I Z AT I O N During the ReHash phase, store pairs of the form (GroupKey→RunningVal) When we want to insert a new tuple into the hash table: → If we find a matching GroupKey, just update the RunningVal appropriately → Else insert a new GroupKey→RunningVal 30 CMU 15-445/645 (Fall 2019) H A S H I N G S U M M A R I Z AT I O N 31 SELECT cid, AVG(s.gpa) FROM student AS s, enrolled AS e WHERE s.sid = e.sid GROUP BY cid 15-445 15-445 15-826 15-721 ⋮ h2 h2 h2 Phase #1 Buckets key value 15-445 (2, 7.32) 15-826 (1, 3.33) 15-721 (1, 2.89) Hash Table CMU 15-445/645 (Fall 2019) H A S H I N G S U M M A R I Z AT I O N 31 SELECT cid, AVG(s.gpa) FROM student AS s, enrolled AS e WHERE s.sid = e.sid GROUP BY cid 15-445 15-445 15-826 15-721 ⋮ h2 h2 h2 Phase #1 Buckets key value 15-445 (2, 7.32) 15-826 (1, 3.33) 15-721 (1, 2.89) Hash Table AVG(col) → (COUNT,SUM) MIN(col) → (MIN) MAX(col) → (MAX) SUM(col) → (SUM) COUNT(col) → (COUNT) Running Totals CMU 15-445/645 (Fall 2019) H A S H I N G S U M M A R I Z AT I O N 31 SELECT cid, AVG(s.gpa) FROM student AS s, enrolled AS e WHERE s.sid = e.sid GROUP BY cid 15-445 15-445 15-826 15-721 ⋮ h2 h2 h2 Phase #1 Buckets key value 15-445 (2, 7.32) 15-826 (1, 3.33) 15-721 (1, 2.89) Hash Table cid AVG(gpa) 15-445 3.66 15-826 3.33 15-721 2.89 Final Result AVG(col) → (COUNT,SUM) MIN(col) → (MIN) MAX(col) → (MAX) SUM(col) → (SUM) COUNT(col) → (COUNT) Running Totals CMU 15-445/645 (Fall 2019) C O S T A N A LY S I S How big of a table can we hash using this approach? → B-1 \"spill partitions\" in Phase #1 → Each should be no more than B blocks big Answer: B ∙ (B-1) → A table of N pages needs about sqrt(N) buffers → Assumes hash distributes records evenly. Use a \"fudge factor\" f>1 for that: we need B ∙ sqrt(f ∙ N) 32 CMU 15-445/645 (Fall 2019) C O N C L U S I O N Choice of sorting vs. hashing is subtle and depends on optimizations done in each case. We already discussed the optimizations for sorting: → Chunk I/O into large blocks to amortize seek+RD costs. → Double-buffering to overlap CPU and I/O. 33 CMU 15-445/645 (Fall 2019) P R O J E C T # 2 You will build a thread-safe linear probing hash table that supports automatic resizing. We define the API for you. You need to provide the implementation. 34 https://15445.courses.cs.cmu.edu/fall2019/project2/ CMU 15-445/645 (Fall 2019) P R O J E C T # 2 TA S K S Page Layouts Hash Table Implementation Table Resizing Concurrency Control Protocol 35 CMU 15-445/645 (Fall 2019) D E V E LO P M E N T H I N T S Follow the textbook semantics and algorithms. You should make sure your page layout are working correctly before switching to the actual hash table itself. Then focus on the single-threaded use case first. Avoid premature optimizations. → Correctness first, performance second. 36 CMU 15-445/645 (Fall 2019) T H I N G S T O N O T E Do not change any file other than the ones that you submit to Gradescope. Rebase on top of the latest BusTub master branch. Post your questions on Piazza or come to TA office hours. 37 CMU 15-445/645 (Fall 2019) P L A G I A R I S M WA R N I N G Your project implementation must be your own work. → You may not copy source code from other groups or the web. → Do not publish your implementation on Github. Plagiarism will not be tolerated. See CMU's Policy on Academic Integrity for additional information. 38 CMU 15-445/645 (Fall 2019) N E X T C L A S S Nested Loop Join Sort-Merge Join Hash Join 39","libVersion":"0.2.2","langs":""}