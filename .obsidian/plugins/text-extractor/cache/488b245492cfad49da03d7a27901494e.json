{"path":".obsidian/plugins/text-extractor/cache/488b245492cfad49da03d7a27901494e.json","text":"Intro to Database Systems 15-445/15-645 Fall 2019 Andy Pavlo Computer Science Carnegie Mellon UniversityAP 07 Tree Indexes Part I CMU 15-445/645 (Fall 2019) A D M I N I S T R I V I A Project #1 is due Fri Sept 27th @ 11:59pm Homework #2 is due Mon Sept 30th @ 11:59pm 2 CMU 15-445/645 (Fall 2019) D ATA S T RU C T U R E S Internal Meta-data Core Data Storage Temporary Data Structures Table Indexes 3 CMU 15-445/645 (Fall 2019) TA B L E I N D E X E S A table index is a replica of a subset of a table's attributes that are organized and/or sorted for efficient access using a subset of those attributes. The DBMS ensures that the contents of the table and the index are logically in sync. 4 CMU 15-445/645 (Fall 2019) TA B L E I N D E X E S It is the DBMS's job to figure out the best index(es) to use to execute each query. There is a trade-off on the number of indexes to create per database. → Storage Overhead → Maintenance Overhead 5 CMU 15-445/645 (Fall 2019) TO D AY ' S A G E N D A B+Tree Overview Design Decisions Optimizations 6 CMU 15-445/645 (Fall 2019) B-T R E E FA M I LY There is a specific data structure called a B-Tree. People also use the term to generally refer to a class of balanced tree data structures: → B-Tree (1971) → B+Tree (1973) → B*Tree (1977?) → Blink-Tree (1981) 7 CMU 15-445/645 (Fall 2019) B-T R E E FA M I LY There is a specific data structure called a B-Tree. People also use the term to generally refer to a class of balanced tree data structures: → B-Tree (1971) → B+Tree (1973) → B*Tree (1977?) → Blink-Tree (1981) 7 CMU 15-445/645 (Fall 2019) B + T R E E A B+Tree is a self-balancing tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions in O(log n). → Generalization of a binary search tree in that a node can have more than two children. → Optimized for systems that read and write large blocks of data. 8 CMU 15-445/645 (Fall 2019) B + T R E E P R O P E R T I E S A B+Tree is an M-way search tree with the following properties: → It is perfectly balanced (i.e., every leaf node is at the same depth). → Every node other than the root, is at least half-full M/2-1 ≤ #keys ≤ M-1 → Every inner node with k keys has k+1 non-null children 9 CMU 15-445/645 (Fall 2019) B + T R E E E X A M P L E 10 Leaf Nodes Inner Node Sibling Pointers 6 7 9 131 3 5 9 CMU 15-445/645 (Fall 2019) B + T R E E E X A M P L E 10 Leaf Nodes <5 <9 ≥9 Inner Node <value>|<key> Sibling Pointers 6 7 9 131 3 5 9<node*>|<key> CMU 15-445/645 (Fall 2019) N O D E S Every B+Tree node is comprised of an array of key/value pairs. → The keys are derived from the attributes(s) that the index is based on. → The values will differ based on whether the node is classified as inner nodes or leaf nodes. The arrays are (usually) kept in sorted key order. 11 CMU 15-445/645 (Fall 2019) B+Tree Leaf Node B + T R E E L E A F N O D E S 12 K1 V1 • • • Kn Vn¤ ¤ Prev Next CMU 15-445/645 (Fall 2019) B+Tree Leaf Node B + T R E E L E A F N O D E S 12 K1 V1 • • • Kn Vn¤ ¤ Prev Next PageID PageID CMU 15-445/645 (Fall 2019) B+Tree Leaf Node B + T R E E L E A F N O D E S 12 Key+ Value K1 V1 • • • Kn Vn¤ ¤ Prev Next ¤ ¤PageID PageID CMU 15-445/645 (Fall 2019) B+Tree Leaf Node B + T R E E L E A F N O D E S 12 Sorted Keys K1 K2 K3 K4 K5 • • • Kn Values ¤ ¤ ¤ ¤ ¤ • • • ¤ ¤ Prev ¤ Next # Level # Slots CMU 15-445/645 (Fall 2019) B+Tree Leaf Node B + T R E E L E A F N O D E S 12 Sorted Keys K1 K2 K3 K4 K5 • • • Kn Values ¤ ¤ ¤ ¤ ¤ • • • ¤ ¤ Prev ¤ Next # Level # Slots CMU 15-445/645 (Fall 2019) L E A F N O D E VA LU E S Approach #1: Record Ids → A pointer to the location of the tuple that the index entry corresponds to. Approach #2: Tuple Data → The actual contents of the tuple is stored in the leaf node. → Secondary indexes have to store the record id as their values. 13 CMU 15-445/645 (Fall 2019) B-T R E E V S . B + T R E E The original B-Tree from 1972 stored keys + values in all nodes in the tree. → More space efficient since each key only appears once in the tree. A B+Tree only stores values in leaf nodes. Inner nodes only guide the search process. 14 CMU 15-445/645 (Fall 2019) B + T R E E I N S E R T Find correct leaf node L. Put data entry into L in sorted order. If L has enough space, done! Otherwise, split L keys into L and a new node L2 → Redistribute entries evenly, copy up middle key. → Insert index entry pointing to L2 into parent of L. To split inner node, redistribute entries evenly, but push up middle key. 15 Source: Chris Re CMU 15-445/645 (Fall 2019) B + T R E E V I S UA L I Z AT I O N https://cmudb.io/btree Source: David Gales (Univ. of San Francisco) 16 CMU 15-445/645 (Fall 2019) B + T R E E D E L E T E Start at root, find leaf L where entry belongs. Remove the entry. If L is at least half-full, done! If L has only M/2-1 entries, → Try to re-distribute, borrowing from sibling (adjacent node with same parent as L). → If re-distribution fails, merge L and sibling. If merge occurred, must delete entry (pointing to L or sibling) from parent of L. 17 Source: Chris Re CMU 15-445/645 (Fall 2019) B + T R E E S I N P R A C T I C E Typical Fill-Factor: 67%. Typical Capacities: → Height 4: 1334 = 312,900,721 entries → Height 3: 1333 = 2,406,104 entries Pages per level: → Level 1 = 1 page = 8 KB → Level 2 = 134 pages = 1 MB → Level 3 = 17,956 pages = 140 MB 18 CMU 15-445/645 (Fall 2019) C LU S T E R E D I N D E X E S The table is stored in the sort order specified by the primary key. → Can be either heap- or index-organized storage. Some DBMSs always use a clustered index. → If a table doesn’t contain a primary key, the DBMS will automatically make a hidden row id primary key. Other DBMSs cannot use them at all. 19 CMU 15-445/645 (Fall 2019) S E L E C T I O N C O N D I T I O N S The DBMS can use a B+Tree index if the query provides any of the attributes of the search key. Example: Index on <a,b,c> → Supported: (a=5 AND b=3) → Supported: (b=3). Not all DBMSs support this. For hash index, we must have all attributes in search key. 20 CMU 15-445/645 (Fall 2019) S E L E C T I O N C O N D I T I O N S 21 Find Key=(A,B) A,C B,B C,C A,C B,AA,A A,B B,B B,C C,C C,D A ≤ A B ≤ C CMU 15-445/645 (Fall 2019) S E L E C T I O N C O N D I T I O N S 21 Find Key=(A,B) A,C B,B C,C A,C B,AA,A A,B B,B B,C C,C C,D Find Key=(A,*) A ≤ A CMU 15-445/645 (Fall 2019) S E L E C T I O N C O N D I T I O N S 21 Find Key=(A,B) A,C B,B C,C A,C B,AA,A A,B B,B B,C C,C C,D Find Key=(A,*) A ≤ A A ≤ B CMU 15-445/645 (Fall 2019) S E L E C T I O N C O N D I T I O N S 21 Find Key=(A,B) Find Key=(*,B) A,C B,B C,C A,C B,AA,A A,B B,B B,C C,C C,D Find Key=(A,*) CMU 15-445/645 (Fall 2019) S E L E C T I O N C O N D I T I O N S 21 Find Key=(A,B) Find Key=(*,B) A,C B,B C,C A,C B,AA,A A,B B,B B,C C,C C,D *,B < C,CFind Key=(A,*) CMU 15-445/645 (Fall 2019) S E L E C T I O N C O N D I T I O N S 21 Find Key=(A,B) Find Key=(*,B) A,C B,B C,C A,C B,AA,A A,B B,B B,C C,C C,D *,B < C,CFind Key=(A,*) * = A B = B * = B B = B CMU 15-445/645 (Fall 2019) B + T R E E D E S I G N C H O I C E S Node Size Merge Threshold Variable Length Keys Non-Unique Indexes Intra-Node Search 22 CMU 15-445/645 (Fall 2019) N O D E S I Z E The slower the storage device, the larger the optimal node size for a B+Tree. → HDD ~1MB → SSD: ~10KB → In-Memory: ~512B Optimal sizes can vary depending on the workload → Leaf Node Scans vs. Root-to-Leaf Traversals 23 CMU 15-445/645 (Fall 2019) M E R G E T H R E S H O L D Some DBMSs do not always merge nodes when it is half full. Delaying a merge operation may reduce the amount of reorganization. It may also be better to just let underflows to exist and then periodically rebuild entire tree. 24 CMU 15-445/645 (Fall 2019) VA R I A B L E L E N G T H K E Y S Approach #1: Pointers → Store the keys as pointers to the tuple’s attribute. Approach #2: Variable Length Nodes → The size of each node in the index can vary. → Requires careful memory management. Approach #3: Padding → Always pad the key to be max length of the key type. Approach #4: Key Map / Indirection → Embed an array of pointers that map to the key + value list within the node. 25 CMU 15-445/645 (Fall 2019) ¤ ¤ ¤ ¤ Andy V1 Obama Prashanth V3 V4 Lin V2 B+Tree Leaf Node K E Y M A P / I N D I R E C T I O N 26 Key+Values ¤ Prev ¤ Next # Level # Slots Sorted Key Map CMU 15-445/645 (Fall 2019) ¤ ¤ ¤ ¤ Andy V1 Obama Prashanth V3 V4 Lin V2 B+Tree Leaf Node K E Y M A P / I N D I R E C T I O N 26 Key+Values ¤ Prev ¤ Next # Level # Slots Sorted Key Map CMU 15-445/645 (Fall 2019) ¤ ¤ ¤ ¤ Andy V1 Obama Prashanth V3 V4 Lin V2 B+Tree Leaf Node K E Y M A P / I N D I R E C T I O N 26 Key+Values ¤ Prev ¤ Next # Level # Slots Sorted Key Map A·¤ L·¤ O·¤ P·¤ CMU 15-445/645 (Fall 2019) N O N -U N I Q U E I N D E X E S Approach #1: Duplicate Keys → Use the same leaf node layout but store duplicate keys multiple times. Approach #2: Value Lists → Store each key only once and maintain a linked list of unique values. 27 CMU 15-445/645 (Fall 2019) B+Tree Leaf Node N O N -U N I Q U E : D U P L I C AT E K E Y S 28 Sorted Keys K1 K1 K1 K2 K2 • • • Kn ¤ Prev ¤ Next # Level # Slots Values ¤ ¤ ¤ ¤ ¤ • • • ¤ CMU 15-445/645 (Fall 2019) B+Tree Leaf Node N O N -U N I Q U E : D U P L I C AT E K E Y S 28 Sorted Keys K1 K1 K1 K2 K2 • • • Kn ¤ Prev ¤ Next # Level # Slots Values ¤ ¤ ¤ ¤ ¤ • • • ¤ CMU 15-445/645 (Fall 2019) B+Tree Leaf Node N O N -U N I Q U E : VA LU E L I S T S 29 Values ¤ ¤ ¤ ¤ ¤• • • ¤ Prev ¤ Next # Level # Slots Sorted Keys K1 K2 K3 K4 K5 • • • Kn CMU 15-445/645 (Fall 2019) I N T R A -N O D E S E A R C H Approach #1: Linear → Scan node keys from beginning to end. Approach #2: Binary → Jump to middle key, pivot left/right depending on comparison. Approach #3: Interpolation → Approximate location of desired key based on known distribution of keys. 30 Find Key=8 5 6 7 8 9 104 CMU 15-445/645 (Fall 2019) I N T R A -N O D E S E A R C H Approach #1: Linear → Scan node keys from beginning to end. Approach #2: Binary → Jump to middle key, pivot left/right depending on comparison. Approach #3: Interpolation → Approximate location of desired key based on known distribution of keys. 30 Find Key=8 5 6 7 8 9 104 5 6 7 8 9 104 CMU 15-445/645 (Fall 2019) I N T R A -N O D E S E A R C H Approach #1: Linear → Scan node keys from beginning to end. Approach #2: Binary → Jump to middle key, pivot left/right depending on comparison. Approach #3: Interpolation → Approximate location of desired key based on known distribution of keys. 30 Find Key=8 5 6 7 8 9 104 5 6 7 8 9 104 CMU 15-445/645 (Fall 2019) I N T R A -N O D E S E A R C H Approach #1: Linear → Scan node keys from beginning to end. Approach #2: Binary → Jump to middle key, pivot left/right depending on comparison. Approach #3: Interpolation → Approximate location of desired key based on known distribution of keys. 30 Find Key=8 5 6 7 8 9 104 5 6 7 8 9 104 CMU 15-445/645 (Fall 2019) I N T R A -N O D E S E A R C H Approach #1: Linear → Scan node keys from beginning to end. Approach #2: Binary → Jump to middle key, pivot left/right depending on comparison. Approach #3: Interpolation → Approximate location of desired key based on known distribution of keys. 30 Find Key=8 5 6 7 8 9 104 5 6 7 8 9 104 CMU 15-445/645 (Fall 2019) I N T R A -N O D E S E A R C H Approach #1: Linear → Scan node keys from beginning to end. Approach #2: Binary → Jump to middle key, pivot left/right depending on comparison. Approach #3: Interpolation → Approximate location of desired key based on known distribution of keys. 30 Find Key=8 5 6 7 8 9 104 5 6 7 8 9 104 5 6 7 8 9 104 Offset: 7-(10-8)=5 CMU 15-445/645 (Fall 2019) O P T I M I Z AT I O N S Prefix Compression Suffix Truncation Bulk Insert Pointer Swizzling 31 CMU 15-445/645 (Fall 2019) P R E F I X C O M P R E S S I O N Sorted keys in the same leaf node are likely to have the same prefix. Instead of storing the entire key each time, extract common prefix and store only unique suffix for each key. → Many variations. 32 robbed robbing robot bed bing ot Prefix: rob CMU 15-445/645 (Fall 2019) S U F F I X T RU N C AT I O N The keys in the inner nodes are only used to \"direct traffic\". → We don't need the entire key. Store a minimum prefix that is needed to correctly route probes into the index. 33 abcdefghijk lmnopqrstuv … …… … CMU 15-445/645 (Fall 2019) S U F F I X T RU N C AT I O N The keys in the inner nodes are only used to \"direct traffic\". → We don't need the entire key. Store a minimum prefix that is needed to correctly route probes into the index. 33 … …… … abc lmn CMU 15-445/645 (Fall 2019) B U L K I N S E R T The fastest/best way to build a B+Tree is to first sort the keys and then build the index from the bottom up. 34 6 7 9 131 3 Keys: 3, 7, 9, 13, 6, 1 Sorted Keys: 1, 3, 6, 7, 9, 13 CMU 15-445/645 (Fall 2019) B U L K I N S E R T The fastest/best way to build a B+Tree is to first sort the keys and then build the index from the bottom up. 34 6 9 6 7 9 131 3 Keys: 3, 7, 9, 13, 6, 1 Sorted Keys: 1, 3, 6, 7, 9, 13 CMU 15-445/645 (Fall 2019) P O I N T E R S W I Z Z L I N G Nodes use page ids to reference other nodes in the index. The DBMS must get the memory location from the page table during traversal. If a page is pinned in the buffer pool, then we can store raw pointers instead of page ids. This avoids address lookups from the page table. 35 6 9 6 71 3Buffer Pool 1 Header 2 Header 3 Header Find Key>3 CMU 15-445/645 (Fall 2019) P O I N T E R S W I Z Z L I N G Nodes use page ids to reference other nodes in the index. The DBMS must get the memory location from the page table during traversal. If a page is pinned in the buffer pool, then we can store raw pointers instead of page ids. This avoids address lookups from the page table. 35 6 9 6 71 3 Page #2Buffer Pool 1 Header 2 Header 3 Header Page #2 → <Page*> Find Key>3 CMU 15-445/645 (Fall 2019) P O I N T E R S W I Z Z L I N G Nodes use page ids to reference other nodes in the index. The DBMS must get the memory location from the page table during traversal. If a page is pinned in the buffer pool, then we can store raw pointers instead of page ids. This avoids address lookups from the page table. 35 6 9 6 71 3 Page #2 Page #3Buffer Pool 1 Header 2 Header 3 Header Page #2 → <Page*> Page #3 → <Page*> Find Key>3 CMU 15-445/645 (Fall 2019) P O I N T E R S W I Z Z L I N G Nodes use page ids to reference other nodes in the index. The DBMS must get the memory location from the page table during traversal. If a page is pinned in the buffer pool, then we can store raw pointers instead of page ids. This avoids address lookups from the page table. 35 6 9 6 71 3Buffer Pool 1 Header 2 Header 3 Header Find Key>3 <Page*> <Page*> CMU 15-445/645 (Fall 2019) C O N C LU S I O N The venerable B+Tree is always a good choice for your DBMS. 36 CMU 15-445/645 (Fall 2019) N E X T C L A S S More B+Trees Tries / Radix Trees Inverted Indexes 37","libVersion":"0.2.2","langs":""}